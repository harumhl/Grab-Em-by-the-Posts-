{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'One', u'CD'), (u'of', u'IN'), (u'China', u'NNP'), (u\"'s\", u'POS'), (u'first', u'JJ'), (u'female', u'NN'), (u'fighter', u'NN'), (u'pilots', u'NNS'), (u'was', u'VBD'), (u'killed', u'VBN'), (u'in', u'IN'), (u'a', u'DT'), (u'training', u'NN'), (u'accident', u'NN'), (u'according', u'VBG'), (u'to', u'TO'), (u'state-run', u'JJ'), (u'media', u'NNS'), (u'reports\\u2026', u'NN'), (u'https', u'NN'), (u'//t.co/DoEZLme8Cq', u'NN')]\n",
      "\n",
      "[u'china', u'female fighter pilots', u'state-run media reports\\u2026 https']\n",
      "\n",
      "[u'One', u'of', u'China', u\"'s\", u'first', u'female', u'fighter', u'pilots', u'was', u'killed', u'in', u'a', u'training', u'accident', u'according', u'to', u'state-run', u'media', u'reports\\u2026', u'https', u't.co/DoEZLme8Cq']\n"
     ]
    }
   ],
   "source": [
    "# https://textblob.readthedocs.io/en/dev/\n",
    "\n",
    "# How to install TextBlob\n",
    "#     1. pip install -U textblob\n",
    "#     2. python -m textblob.download_corpora\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob(dfT['text'][0]) # run json-to-pandas\n",
    "\n",
    "# Part-of-speech Tagging\n",
    "print blob.tags\n",
    "print\n",
    "\n",
    "# Noun Phrase Extraction¶\n",
    "print blob.noun_phrases\n",
    "print \n",
    "\n",
    "# Tokenization\n",
    "print blob.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0166666666667\n",
      "\n",
      "One---One\n",
      "of---of\n",
      "China---China\n",
      "'s---'s\n",
      "first---first\n",
      "female---female\n",
      "fighter---fighter\n",
      "pilots---pilot\n",
      "was---be\n",
      "killed---kill\n",
      "in---in\n",
      "a---a\n",
      "training---train\n",
      "accident---accident\n",
      "according---accord\n",
      "to---to\n",
      "state-run---state-run\n",
      "media---media\n",
      "reports…---reports…\n",
      "https---https\n",
      "t.co/DoEZLme8Cq---t.co/DoEZLme8Cq\n"
     ]
    }
   ],
   "source": [
    "# The subjectivity is a float within the range [0.0, 1.0] \n",
    "# where 0.0 is very objective and 1.0 is very subjective\n",
    "for sentence in blob.sentences:\n",
    "    print sentence.sentiment.polarity\n",
    "print\n",
    "\n",
    "# Lemmatize each word\n",
    "for sentence in blob.sentences:    \n",
    "    for word in sentence.words:\n",
    "        print \"%s---%s\" % (word, word.lemmatize('v')) # 'v' for 'verb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.nltk.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank # to draw a parse tree\n",
    "\n",
    "sentence = dfT['text'][0] # run json-to-pandas\n",
    "\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "\n",
    "# Identify named entities - Make parse tree?\n",
    "# You might need to call nltk.download() and down load some packages\n",
    "entities = nltk.chunk.ne_chunk(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1500 instances, test on 500 instances\n",
      "accuracy: 0.728\n",
      "Most Informative Features\n",
      "             magnificent = True              pos : neg    =     15.0 : 1.0\n",
      "             outstanding = True              pos : neg    =     13.6 : 1.0\n",
      "               insulting = True              neg : pos    =     13.0 : 1.0\n",
      "              vulnerable = True              pos : neg    =     12.3 : 1.0\n",
      "               ludicrous = True              neg : pos    =     11.8 : 1.0\n",
      "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
      "             uninvolving = True              neg : pos    =     11.7 : 1.0\n",
      "              astounding = True              pos : neg    =     10.3 : 1.0\n",
      "             fascination = True              pos : neg    =     10.3 : 1.0\n",
      "                 idiotic = True              neg : pos    =      9.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Example from http://streamhacker.com/2010/05/10/text-classification-sentiment-analysis-naive-bayes-classifier/\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    " \n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    " \n",
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')\n",
    " \n",
    "negfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\n",
    "posfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in posids]\n",
    " \n",
    "negcutoff = len(negfeats)*3/4\n",
    "poscutoff = len(posfeats)*3/4\n",
    " \n",
    "trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]\n",
    "testfeats = negfeats[negcutoff:] + posfeats[poscutoff:]\n",
    "print 'train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats))\n",
    " \n",
    "classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "print 'accuracy:', nltk.classify.util.accuracy(classifier, testfeats)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Supervised Learning w/ manual scripting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 2)\n",
      "(72, 2)\n"
     ]
    }
   ],
   "source": [
    "# Task 1: Load the texts\n",
    "import pandas as pd\n",
    "import glob, os         # for reading all .txt files\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "cutoff = 800\n",
    "\n",
    "# Read sample texts\n",
    "sample = pd.read_csv('/Users/Haru/Documents/! College/4. Fall 2016/489Project/sample_data_results.csv') \n",
    "# Pos = 1, Neg = -1\n",
    "sample['Answer.sentiment'] = sample['Answer.sentiment'].map({'Positive':1, 'Negative':-1})\n",
    "\n",
    "train = pd.DataFrame({'label':sample['Answer.sentiment'][:cutoff], 'texts':sample['Input.content'][:cutoff]})\n",
    "test  = pd.DataFrame({'label':sample['Answer.sentiment'][cutoff:], 'texts':sample['Input.content'][cutoff:]})\n",
    "\n",
    "print train.shape\n",
    "print test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 70 0 0 0 \t 0.6389\n",
      "1 70 0 0 1 \t 0.8056\n",
      "1 70 0 0 2 \t 0.5833\n",
      "1 70 0 0 3 \t 0.6389\n",
      "1 70 0 0 4 \t 0.6667\n",
      "1 70 0 0 5 \t 0.0487\n",
      "1 70 0 0 6 \t -0.0192\n",
      "1 70 0 0 7 \t -0.0192\n",
      "1 70 0 0 8 \t 0.0822\n",
      "1 70 0 0 10 \t 0.7222\n",
      "1 70 0 0 11 \t -0.0854\n",
      "1 70 0 0 12 \t 0.5833\n",
      "1 70 0 0 13 \t 0.6389\n",
      "1 70 0 0 14 \t 0.0865\n",
      "1 70 0 0 15 \t 0.4722\n",
      "1 70 0 1 0 \t 0.6389\n",
      "1 70 0 1 1 \t 0.8056\n",
      "1 70 0 1 2 \t 0.5833\n",
      "1 70 0 1 3 \t 0.6389\n",
      "1 70 0 1 4 \t 0.6111\n",
      "1 70 0 1 5 \t 0.0487\n",
      "1 70 0 1 6 \t -0.0192\n",
      "1 70 0 1 7 \t -0.0192\n",
      "1 70 0 1 8 \t 0.0799\n",
      "1 70 0 1 10 \t 0.6667\n",
      "1 70 0 1 11 \t -0.2464\n",
      "1 70 0 1 12 \t 0.5833\n",
      "1 70 0 1 13 \t 0.6389\n",
      "1 70 0 1 14 \t 0.0865\n",
      "1 70 0 1 15 \t 0.4722\n",
      "1 70 1 0 0 \t 0.6389\n",
      "1 70 1 0 1 \t 0.8056\n",
      "1 70 1 0 2 \t 0.5833\n",
      "1 70 1 0 3 \t 0.6389\n",
      "1 70 1 0 4 \t 0.5278\n",
      "1 70 1 0 5 \t 0.0487\n",
      "1 70 1 0 6 \t -0.0192\n",
      "1 70 1 0 7 \t -0.0192\n",
      "1 70 1 0 8 \t 0.0809\n",
      "1 70 1 0 10 \t 0.6944\n",
      "1 70 1 0 11 \t -0.0616\n",
      "1 70 1 0 12 \t 0.5833\n",
      "1 70 1 0 13 \t 0.6389\n",
      "1 70 1 0 14 \t 0.0865\n",
      "1 70 1 0 15 \t 0.4722\n",
      "1 70 1 1 0 \t 0.7222\n",
      "1 70 1 1 1 \t 0.7222\n",
      "1 70 1 1 2 \t 0.7222\n",
      "1 70 1 1 3 \t 0.7222\n",
      "1 70 1 1 4 \t 0.7500\n",
      "1 70 1 1 5 \t -0.0489\n",
      "1 70 1 1 6 \t -0.0192\n",
      "1 70 1 1 7 \t -0.0192\n",
      "1 70 1 1 8 \t 0.0091\n",
      "1 70 1 1 10 \t 0.6389\n",
      "1 70 1 1 11 \t -0.0103\n",
      "1 70 1 1 12 \t 0.5833\n",
      "1 70 1 1 13 \t 0.7222\n",
      "1 70 1 1 14 \t -0.4425\n",
      "1 70 1 1 15 \t 0.7222\n",
      "1 71 0 0 0 \t 0.6389\n",
      "1 71 0 0 1 \t 0.8056\n",
      "1 71 0 0 2 \t 0.5833\n",
      "1 71 0 0 3 \t 0.6389\n",
      "1 71 0 0 4 \t 0.6389\n",
      "1 71 0 0 5 \t 0.0487\n",
      "1 71 0 0 6 \t -0.0192\n",
      "1 71 0 0 7 \t -0.0192\n",
      "1 71 0 0 8 \t 0.0814\n",
      "1 71 0 0 10 \t 0.6944\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-b53f13b25fb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m                         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"%d %d %d %d %d \\t %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tf_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tf_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"%d %d %d %d %d \\t %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tf_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haru/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[0;32m--> 314\u001b[0;31m                                             random_state=random_state)\n\u001b[0m\u001b[1;32m    315\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haru/anaconda/lib/python2.7/site-packages/sklearn/ensemble/base.pyc\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0m_set_random_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haru/anaconda/lib/python2.7/site-packages/sklearn/ensemble/base.pyc\u001b[0m in \u001b[0;36m_set_random_states\u001b[0;34m(estimator, random_state)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'random_state'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__random_state'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mto_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_RAND_SEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mto_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Task 4: feature engineering\n",
    "for h in range(1,30): # min_df\n",
    "    for i in range(70,100): # max_df\n",
    "        for j in range(0,2): # stop_words: k=0 'engl' k=1 none\n",
    "            for k in range(0,2): # k=0 CountVectorizer (count), k=1 TfidfVectorizer (weighed)\n",
    "                for l in range(0,16): # l=0 MultinomialNB, l=1 GaussianNB, l=2 BernoulliNB              \n",
    "                                      # l=3 LogisticRegression, l=4 SGDClassifier, l=5 Ridge\n",
    "                                      # l=6 ElasticNet, l=7 LassoLars, l=8 SGDRegressor\n",
    "                                      # l=9 ARDRegression, l=10 GradientBoostingClassifier, l=11 RandomForestRegressor\n",
    "                                      # l=12 SVC, l=13 LinearSVC, l=14 SVR, l=15 KNeighborsClassifier \n",
    "\n",
    "                    if j==0 & k==0:\n",
    "                        tf_vectorizer = CountVectorizer(max_df=i/100.0, min_df=h/100.0, stop_words='english')\n",
    "                    elif j==1 & k==0:\n",
    "                        tf_vectorizer = CountVectorizer(max_df=i/100.0, min_df=h/100.0)\n",
    "                    elif j==0 & k==1:\n",
    "                        tf_vectorizer = TfidfVectorizer(max_df=i/100.0, min_df=h/100.0, stop_words='english')\n",
    "                    elif j==1 & k==1:\n",
    "                        tf_vectorizer = TfidfVectorizer(max_df=i/100.0, min_df=h/100.0)\n",
    "\n",
    "                    train_tf_ = tf_vectorizer.fit_transform(train['texts'].values)\n",
    "                    test_tf_  = tf_vectorizer.transform(test['texts'].values)\n",
    "\n",
    "                    if l==0:\n",
    "                        clf = MultinomialNB()\n",
    "                    elif l==1:\n",
    "                        clf = GaussianNB()\n",
    "                    elif l==2:\n",
    "                        clf = BernoulliNB()\n",
    "                    elif l==3:\n",
    "                        clf = LogisticRegression()\n",
    "                    elif l==4:\n",
    "                        clf = SGDClassifier()\n",
    "                    elif l==5:\n",
    "                        clf = Ridge()\n",
    "                    elif l==6:\n",
    "                        clf = ElasticNet()\n",
    "                    elif l==7:\n",
    "                        clf = LassoLars()\n",
    "                    elif l==8:\n",
    "                        clf = SGDRegressor()\n",
    "                    elif l==9:\n",
    "                        continue #skip - takes too long\n",
    "                        clf = ARDRegression()\n",
    "                    elif l==10:\n",
    "                        clf = GradientBoostingClassifier()\n",
    "                    elif l==11:\n",
    "                        clf = RandomForestRegressor()\n",
    "                    elif l==12:\n",
    "                        clf = SVC()\n",
    "                    elif l==13:\n",
    "                        clf = LinearSVC()\n",
    "                    elif l==14:\n",
    "                        clf = SVR()\n",
    "                    elif l==15:\n",
    "                        clf = KNeighborsClassifier()\n",
    "                    \n",
    "                    if l==1 or l==5 or l==7 or l==9 or l==10:\n",
    "                        clf.fit(train_tf_.toarray(), train['label'])\n",
    "                        print \"%d %d %d %d %d \\t %.4f\" % (h,i,j,k,l,clf.score(test_tf_.toarray(), test['label']))\n",
    "                    else:\n",
    "                        clf.fit(train_tf_, train['label'])\n",
    "                        print \"%d %d %d %d %d \\t %.4f\" % (h,i,j,k,l,clf.score(test_tf_, test['label']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 20,000+ possibilities and running 8000+ cases, <br>\n",
    "It never hit 0.7.. ->> For train:test = 1:1 size\n",
    "\n",
    "Train:test = 10:1 size. I do get up to 0.8+ <br>\n",
    "Now we also have up to (more reasonable) 14400 cases (all expected to run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning w/ TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  20%|██        | 15/75 [01:27<09:55,  9.92s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.730170602345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  39%|███▊      | 29/75 [06:32<13:10, 17.18s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.730170602345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  60%|██████    | 45/75 [13:02<10:46, 21.53s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.739191581365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  79%|███████▊  | 59/75 [19:13<07:42, 28.88s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.739191581365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline: DecisionTreeClassifier(Nystroem(input_matrix, 19, 0.53000000000000003, 24))\n",
      "0.694951472663\n",
      "0 1 90 0 5 4 3 9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  20%|██        | 15/75 [02:29<17:58, 17.98s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.752644927536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  41%|████▏     | 31/75 [06:50<14:50, 20.25s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.752644927536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  59%|█████▊    | 44/75 [06:55<01:26,  2.79s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.752644927536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  81%|████████▏ | 61/75 [07:00<00:03,  4.00pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.752644927536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline: DecisionTreeClassifier(input_matrix)\n",
      "0.672018348624\n",
      "0 1 90 0 5 4 3 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  20%|██        | 20/100 [02:51<16:01, 12.02s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.763276972625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  42%|████▏     | 42/100 [08:27<17:21, 17.96s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.763276972625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  59%|█████▉    | 59/100 [08:31<00:55,  1.35s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.763276972625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  83%|████████▎ | 83/100 [09:39<00:08,  2.00pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.763276972625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline: DecisionTreeClassifier(input_matrix)\n",
      "0.692401960784\n",
      "0 1 90 0 5 4 4 9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  21%|██        | 21/100 [00:01<00:07, 11.09pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.72766798419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  38%|███▊      | 38/100 [00:03<00:05, 10.74pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.72766798419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  57%|█████▋    | 57/100 [00:06<00:09,  4.66pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.732213438735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  81%|████████  | 81/100 [00:54<00:10,  1.78pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.732213438735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:   1%|          | 1/90 [00:00<00:09,  9.71pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline: LinearSVC(Binarizer(input_matrix, 0.34000000000000002), 0.42999999999999999, 49, True)\n",
      "0.729801604052\n",
      "0 1 90 0 5 4 4 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  18%|█▊        | 16/90 [01:02<03:20,  2.71s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.69483226918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  37%|███▋      | 33/90 [03:04<04:45,  5.01s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.69483226918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  54%|█████▍    | 49/90 [03:05<00:20,  1.97pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.69483226918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  69%|██████▉   | 62/90 [03:10<00:12,  2.19pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.69483226918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  84%|████████▍ | 76/90 [03:11<00:01,  9.49pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5 - Current best internal CV score: 0.69483226918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:   0%|          | 0/90 [00:00<?, ?pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline: DecisionTreeClassifier(RBFSampler(input_matrix, 0.55000000000000004))\n",
      "0.730289757412\n",
      "0 1 90 0 5 5 3 9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  19%|█▉        | 17/90 [01:05<04:29,  3.69s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.728938923395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  37%|███▋      | 33/90 [03:41<08:59,  9.47s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.731247412008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  51%|█████     | 46/90 [03:42<01:12,  1.65s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.731247412008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  64%|██████▍   | 58/90 [03:43<00:08,  3.81pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.731247412008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  84%|████████▍ | 76/90 [04:33<00:17,  1.26s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5 - Current best internal CV score: 0.731247412008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:   1%|          | 1/120 [00:00<00:12,  9.31pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline: DecisionTreeClassifier(input_matrix)\n",
      "0.695038746631\n",
      "0 1 90 0 5 5 3 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  17%|█▋        | 20/120 [02:38<13:29,  8.10s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.732443329617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  32%|███▎      | 39/120 [04:05<09:01,  6.68s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.732443329617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  48%|████▊     | 57/120 [07:54<11:35, 11.03s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.732443329617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  64%|██████▍   | 77/120 [13:36<12:31, 17.48s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.732443329617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  82%|████████▏ | 98/120 [18:51<10:07, 27.63s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5 - Current best internal CV score: 0.732443329617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline: RandomForestClassifier(input_matrix)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Optimization Progress:   0%|          | 0/120 [00:00<?, ?pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.761808367072\n",
      "0 1 90 0 5 5 4 9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  18%|█▊        | 21/120 [00:44<03:43,  2.26s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.710939676266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  32%|███▏      | 38/120 [04:22<13:57, 10.21s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.710939676266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  49%|████▉     | 59/120 [04:30<00:23,  2.62pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.710939676266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  64%|██████▍   | 77/120 [04:40<00:16,  2.56pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.710939676266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  82%|████████▏ | 98/120 [04:48<00:12,  1.82pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5 - Current best internal CV score: 0.710939676266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:   0%|          | 0/75 [00:00<?, ?pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline: LinearSVC(input_matrix, 9.0, 38, True)\n",
      "0.691016324381\n",
      "0 1 90 0 5 5 4 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  21%|██▏       | 16/75 [01:18<04:24,  4.49s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.712237583205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  40%|████      | 30/75 [05:27<18:44, 24.99s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.712237583205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  59%|█████▊    | 44/75 [13:02<17:29, 33.84s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.712237583205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  77%|███████▋  | 58/75 [16:20<03:48, 13.44s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.712237583205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline: ExtraTreesClassifier(Binarizer(input_matrix, 0.27000000000000002), 14, 0.94000000000000006)\n",
      "0.697577194022\n",
      "0 1 90 0 6 4 3 9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  21%|██▏       | 16/75 [03:25<20:30, 20.85s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.75966951567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  39%|███▊      | 29/75 [10:00<26:20, 34.37s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.75966951567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  60%|██████    | 45/75 [10:07<00:12,  2.38pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.75966951567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  83%|████████▎ | 62/75 [10:09<00:01,  8.96pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.759811965812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline: LogisticRegression(input_matrix, 0.98999999999999999, 5, True)\n",
      "0.71221449851\n",
      "0 1 90 0 6 4 3 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  20%|██        | 20/100 [03:30<07:44,  5.81s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.732525126622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  37%|███▋      | 37/100 [11:04<33:28, 31.88s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.732525126622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  51%|█████     | 51/100 [21:21<44:59, 55.09s/pipeline]"
     ]
    }
   ],
   "source": [
    "for i in range(0,2): # 'Negative' from sample = -1 or 0\n",
    "    for j in range(1,10): # min_df\n",
    "        for k in range(90,100): # max_df\n",
    "            for l in range(0,2): # l=0 CountVectorizer (count), l=1 TfidfVectorizer (weighed)\n",
    "                for m in range(5,10): # train:test = m/10 : (1-m/10) so 50:50 to 90:10\n",
    "                    for n in range(4,6): # generation (# of TPOT iteration)\n",
    "                        for p in range(3,5): # pop_size 5p \n",
    "                            for q in range(9,11): # k-fold number\n",
    "                                print \"\"    \n",
    "\n",
    "                                sample = pd.read_csv('/Users/Haru/Documents/! College/4. Fall 2016/489Project/sample_data_results.csv') \n",
    "\n",
    "                                # label ('positive','Negative') ->> (#,#) (e.g. (1,-1) or (1,0))\n",
    "                                if i==0:\n",
    "                                    sample['Answer.sentiment'] = sample['Answer.sentiment'].map({'Positive':1, 'Negative':-1})\n",
    "                                elif i==1:\n",
    "                                    sample['Answer.sentiment'] = sample['Answer.sentiment'].map({'Positive':1, 'Negative':0})\n",
    "\n",
    "                                if l==0:\n",
    "                                    tf_vectorizer = CountVectorizer(min_df=j/100.0, max_df=k/100.0)\n",
    "                                elif l==1:\n",
    "                                    tf_vectorizer = TfidfVectorizer(min_df=j/100.0, max_df=k/100.0)\n",
    "\n",
    "                                sample_input_tf  = tf_vectorizer.fit_transform(sample['Input.content'].values)\n",
    "\n",
    "                                X_train, X_test, y_train, y_test = train_test_split(sample_input_tf, sample['Answer.sentiment'].values,\n",
    "                                                                    train_size=m/10.0, test_size=(1-m/10.0))#, random_state=)\n",
    "\n",
    "                                # Official website example: gen=5, pop_size=20, verbo=2\n",
    "                                tpot = TPOTClassifier(generations=n, population_size=5*p, num_cv_folds=q,\n",
    "                                                      verbosity=2)\n",
    "                                tpot.fit(X_train, y_train)\n",
    "                                print(tpot.score(X_test, y_test))\n",
    "                                print \"%d %d %d %d %d %d %d %d\" % (i,j,k,l,m,n,p,q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer, Pos=1 Neg=-1, train:test=75:25, size=872 in TPOT = 0.78 <br>\n",
    "CountVectorizer, Pos=1 Neg=-1, train:test=92:08, size=872 in TPOT = 0.78 <br>\n",
    "CountVectorizer, Pos=1 Neg =0, train:test=92:08, size=872 in TPOT = 0.86 <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "trump donald presidency nigel farage loathsome creature calls brexit leader obama inside national guru security mind change climate experts increasingly\n",
      "Topic #1:\n",
      "trump new york protesters win yorkers database tweets unfair hours info light calling mayor nyc deleted undocumented praise calls denounce\n",
      "Topic #2:\n",
      "rt help trump author historian lady future shyness cnnnewsroom detect melania speaker ryan deportation erecting force planning paul cnnpolitics allies\n",
      "Topic #3:\n",
      "america like americans hope trump promised watching does reid white fear feel tears innocent celebrate nationalists breath says deep everybody\n",
      "Topic #4:\n",
      "trump obamacare pulling going pol rug backing repeal day interview pledge appeared country end needs replace open agreed work democrats\n",
      "Topic #5:\n",
      "trump says kelly denies advance saw megyn debate report book question children gets advising rudy cnnsotu government giuliani jobs lead\n",
      "Topic #6:\n",
      "president cast ballots million unqualified candidates voters nearly 18 lady help trump win historian cities aid rendell fearful rt future\n",
      "Topic #7:\n",
      "election packing resolve american fear presidential express muslims shock start obama calls trump nigel loathsome creature leader brexit supporter farage\n",
      "Topic #8:\n",
      "trump donald elect president life voted clinton air win asranomani won state team administration new campaign protests muslim says force\n",
      "Topic #9:\n",
      "trump donald clinton hillary white people president house paul ryan says elect hate presidential sources just reince priebus chief staff\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   #max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(train['texts'].values)\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                #max_features=n_features,\n",
    "                                stop_words='english')\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(train['texts'].values)\n",
    "\n",
    "lda = LatentDirichletAllocation(#n_topics=n_topics, \n",
    "                                max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "lda.fit(tf)\n",
    "\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble & Bagging (Bootstrap AGgregating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Nope... http://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So text extraction + ..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Task 1: Load the texts\n",
    "import pandas as pd\n",
    "import glob, os         # for reading all .txt files\n",
    "import csv\n",
    "import numpy as np\n",
    "from textblob import TextBlob # use kernel Python[Root]\n",
    "\n",
    "cutoff = 436\n",
    "\n",
    "# Read sample texts\n",
    "sample = pd.read_csv('/Users/Haru/Documents/! College/4. Fall 2016/489Project/sample_data_results.csv') \n",
    "\n",
    "# Lemmatize\n",
    "new_sample = pd.DataFrame(columns=(\"Input.content\", \"Answer.sentiment\"))\n",
    "i=0\n",
    "for text in sample['Input.content']:\n",
    "    blob = TextBlob(text)\n",
    "    newtexts = \"\"\n",
    "\n",
    "    for sentence in blob.sentences:\n",
    "        newtext = \"\"\n",
    "#        print sentence.dict\n",
    "\n",
    "        for word in sentence.words:\n",
    "            newtext += \" \" + word.lemmatize('v') # 'v' for 'verb'\n",
    "\n",
    "        newtexts += newtext\n",
    "        new_sample.loc[i] = newtexts\n",
    "        i += 1\n",
    "\n",
    "i=0\n",
    "for answer in sample['Answer.sentiment']: # updating answers\n",
    "    new_sample['Answer.sentiment'].loc[i] = answer\n",
    "    i += 1\n",
    "    \n",
    "sample = new_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.DataFrame({'label':sample['Answer.sentiment'][:cutoff], 'texts':sample['Input.content'][:cutoff]})\n",
    "test  = pd.DataFrame({'label':sample['Answer.sentiment'][cutoff:], 'texts':sample['Input.content'][cutoff:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6 0 0 1 - 0.7778\n",
      "1 6 0 0 2 - 0.6389\n",
      "1 6 0 1 1 - 0.7778\n",
      "1 6 0 1 2 - 0.6389\n",
      "1 6 1 0 1 - 0.7778\n",
      "1 6 1 0 2 - 0.6389\n",
      "1 6 1 1 1 - 0.7222\n",
      "1 6 1 1 2 - 0.6944\n",
      "1 7 0 0 1 - 0.8056\n",
      "1 7 0 0 2 - 0.6389\n",
      "1 7 0 1 1 - 0.8056\n",
      "1 7 0 1 2 - 0.6389\n",
      "1 7 1 0 1 - 0.8056\n",
      "1 7 1 0 2 - 0.6389\n",
      "1 7 1 1 1 - 0.7222\n",
      "1 7 1 1 2 - 0.6389\n",
      "1 8 0 0 1 - 0.8056\n",
      "1 8 0 0 2 - 0.6389\n",
      "1 8 0 1 1 - 0.8056\n",
      "1 8 0 1 2 - 0.6389\n",
      "1 8 1 0 1 - 0.8056\n",
      "1 8 1 0 2 - 0.6389\n",
      "1 8 1 1 1 - 0.7222\n",
      "1 8 1 1 2 - 0.6389\n",
      "1 9 0 0 1 - 0.8056\n",
      "1 9 0 0 2 - 0.5833\n",
      "1 9 0 1 1 - 0.8056\n",
      "1 9 0 1 2 - 0.5833\n",
      "1 9 1 0 1 - 0.8056\n",
      "1 9 1 0 2 - 0.5833\n",
      "1 9 1 1 1 - 0.7222\n",
      "1 9 1 1 2 - 0.6389\n",
      "1 10 0 0 1 - 0.8056\n",
      "1 10 0 0 2 - 0.6389\n",
      "1 10 0 1 1 - 0.8056\n",
      "1 10 0 1 2 - 0.6389\n",
      "1 10 1 0 1 - 0.8056\n",
      "1 10 1 0 2 - 0.6389\n",
      "1 10 1 1 1 - 0.7222\n",
      "1 10 1 1 2 - 0.6944\n",
      "1 11 0 0 1 - 0.8056\n",
      "1 11 0 0 2 - 0.6389\n",
      "1 11 0 1 1 - 0.8056\n",
      "1 11 0 1 2 - 0.6389\n",
      "1 11 1 0 1 - 0.8056\n",
      "1 11 1 0 2 - 0.6389\n",
      "1 11 1 1 1 - 0.7222\n",
      "1 11 1 1 2 - 0.6944\n",
      "1 12 0 0 1 - 0.8056\n",
      "1 12 0 0 2 - 0.6389\n",
      "1 12 0 1 1 - 0.8056\n",
      "1 12 0 1 2 - 0.6389\n",
      "1 12 1 0 1 - 0.8056\n",
      "1 12 1 0 2 - 0.6389\n",
      "1 12 1 1 1 - 0.7222\n",
      "1 12 1 1 2 - 0.6944\n",
      "1 13 0 0 1 - 0.8056\n",
      "1 13 0 0 2 - 0.6389\n",
      "1 13 0 1 1 - 0.8056\n",
      "1 13 0 1 2 - 0.6389\n",
      "1 13 1 0 1 - 0.8056\n",
      "1 13 1 0 2 - 0.6389\n",
      "1 13 1 1 1 - 0.7222\n",
      "1 13 1 1 2 - 0.6944\n",
      "1 14 0 0 1 - 0.8056\n",
      "1 14 0 0 2 - 0.6389\n",
      "1 14 0 1 1 - 0.8056\n",
      "1 14 0 1 2 - 0.6389\n",
      "1 14 1 0 1 - 0.8056\n",
      "1 14 1 0 2 - 0.6389\n",
      "1 14 1 1 1 - 0.7222\n",
      "1 14 1 1 2 - 0.6944\n",
      "1 15 0 0 1 - 0.8056\n",
      "1 15 0 0 2 - 0.5833\n",
      "1 15 0 1 1 - 0.8056\n",
      "1 15 0 1 2 - 0.5833\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e18b73c0799f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                         \u001b[0mtf_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                     \u001b[0mtrain_tf_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'texts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                     \u001b[0mtest_tf_\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'texts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haru/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 839\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haru/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haru/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 241\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Haru/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mtoken_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtoken_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_stop_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Task 4: feature engineering\n",
    "for h in range(1,30): # min_df\n",
    "    for i in range(h+5,100): # max_df\n",
    "        for j in range(0,2): # stop_words: k=0 'engl' k=1 none\n",
    "            for k in range(0,2): # k=0 CountVectorizer (count), k=1 TfidfVectorizer (weighed)\n",
    "                for l in range(0,3): # l=0 MultinomialNB, l=1 GaussianNB, l=2 BernoulliNB              \n",
    "\n",
    "                    if j==0 & k==0:\n",
    "                        tf_vectorizer = CountVectorizer(max_df=i/100.0, min_df=h/100.0, stop_words='english')\n",
    "                    elif j==1 & k==0:\n",
    "                        tf_vectorizer = CountVectorizer(max_df=i/100.0, min_df=h/100.0)\n",
    "                    elif j==0 & k==1:\n",
    "                        tf_vectorizer = TfidfVectorizer(max_df=i/100.0, min_df=h/100.0, stop_words='english')\n",
    "                    elif j==1 & k==1:\n",
    "                        tf_vectorizer = TfidfVectorizer(max_df=i/100.0, min_df=h/100.0)\n",
    "\n",
    "                    train_tf_ = tf_vectorizer.fit_transform(train['texts'].values)\n",
    "                    test_tf_  = tf_vectorizer.transform(test['texts'].values)\n",
    "\n",
    "                    if l==0:\n",
    "                        clf = MultinomialNB()\n",
    "                    elif l==1:\n",
    "                        clf = GaussianNB()\n",
    "                    elif l==2:\n",
    "                        clf = BernoulliNB()\n",
    "\n",
    "                    if l==0 | l==2:\n",
    "                        clf.fit(train_tf_, train['label'])\n",
    "                        print \"%d %d %d %d %d - %.4f\" % (h,i,j,k,l,clf.score(test_tf_, test['label']))\n",
    "                    elif l==1:\n",
    "                        clf.fit(train_tf_.toarray(), train['label'])\n",
    "                        print \"%d %d %d %d %d - %.4f\" % (h,i,j,k,l,clf.score(test_tf_.toarray(), test['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
